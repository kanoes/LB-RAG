1）RAG 的提出 → 多语言需求的出现
RAG 通过“检索+生成”把外部知识接进 LLM，改善事实性与可溯源性（Lewis et al., 2020）。问题是早期研究几乎纯英文，实际应用常遇到“用户语言 ≠ 知识语言”。（这里点出动机即可）

2）从跨语言 QA 到 mRAG 基线

早期跨语言 QA 数据集（XQA、XOR-QA）让我们看到：问题语言与证据语言不一致时，系统难度大幅提升；但它们多以英文证据为主，对“多语检索+跨语整合”评测不足。

mRAG 基线：Chirkova 等（2024）系统搭建了 13 语种 mRAG pipeline，指出需要显式的输出语言控制（不然易答成英文）、评价需适配多语言、以及非拉丁文字中 code-switching 高发等问题。

3）XRAG：更贴近真实场景的跨语言 RAG 基准

用新闻构造“必须依赖外部检索”的复杂问题；每条样本都含2 篇支持文 + 6 篇干扰文，分别覆盖单语/多语检索两种设定，评估 5 个 LLM；并通过语言正确性检查 + LLM 多裁判表决评估事实性。结论如前所述两个痛点。

4）最新工作暴露的共性难题与启示

语言偏好：mRAG 检索器偏向高资源或查询语言；生成器偏向查询语言/拉丁字母，导致不一致输出。提出 DKM‑RAG：把“外部翻译后的证据”和“模型改写/内隐知识”双通道融合，能缓解偏好并提升性能。

跨语证据利用一致性：LLM 能从“异语言段落”提取信息，但难以用目标语言完整作答；而且同语种干扰段落对答案伤害更大。

小结（“研究动机”末段）：基线 mRAG 暴露出输出语言控制与跨语推理两大短板；XRAG 将这两点具象化为可测指标；最新研究提示**“证据翻译/统一、双通道融合、对干扰稳健性”是有效突破口，但也引入成本与信息损失**的新权衡。