# M​RAG：多语言检索增强生成的基线探索  
Nadezhda Chirkova 等，2024-07

## 1. 研究动机  
1. RAG（检索增强生成）已被证明能提升大语言模型的事实性与时效性，但几乎只在英文场景下评估。  
2. 真正的跨语言应用（用户查询与知识库可能分属 13 种语言）尚缺统一基线和系统性分析。  
3. 论文目标：  
   - 构建一个可复现的 mRAG（multilingual RAG）整体 pipeline；  
   - 拆解检索、重排序、生成三个环节在多语言条件下的关键设计；  
   - 提出评测指标与 prompt 工程的改动要点，并公开代码。

## 2. 方法框架  
```mermaid
graph LR
Q[用户多语言查询] -->|翻译可选| R[多语言检索器]
R --> Topk[相关文档 Top-k]
Topk --> GE[多语言生成模型]
GE --> A[最终回答(用户语言)]
```

### 2.1 检索阶段  
- **稠密检索器**：对比 mT5-base、LaBSE、mContriever 等 off-the-shelf encoder。  
- **硬负样本构造**：对每种语言分别利用 BM25 选取 top-n 非相关段落，缓解语言分布失衡。  
- **跨语言召回**：实验发现“查询翻译→英文检索”在低资源语言上 recall 受限，直接多语检索效果更稳定。

### 2.2 生成阶段  
- 采用 **mT5-XL** 作为主力生成器。  
- **Prompt 工程**：  
  1. 将检索结果拼接为 <context> 段；  
  2. 指令模板中显式指定“请用 **查询原语言** 作答”；  
  3. 若检索语言与生成语言不一致，需加入 language tag 或示例对话防止模型输出英文。  
- **温度/Top-p** 调优：多语场景下低温度仍可保持流畅性，降低幻觉。

### 2.3 评测指标调整  
- EM/F1 在多语环境易受大小写、变音符等影响；作者基于原 TyDiQA-GoldP 指标做两处修订：  
  1. 统一 Unicode NFC；  
  2. 允许部分实体同义拼写作松匹配。

## 3. 数据与实验  
| 任务 | 语言数 | 数据说明 | 用途 |
| --- | --- | --- | --- |
| XOR-TyDi QA | 7 | 原生跨语问答 | 主要评测 |
| MKQA-RAG | 13 | 作者改写版，含 1.6M 维基段落 | ablation |
| BEIR-Multilingual | 8 | 检索评估 | Retriever 预训练 |

### 3.1 关键结果  
1. **检索器比较**：mContriever-multi 在 R@100 上比翻译检索高 6-12 pp。  
2. **生成质量**：在 XOR-TyDi 上，mRAG 相比 vanilla mT5（无检索）平均 F1 +7.8；  
3. **低资源语言**（如 Telugu）：RAG 带来最大增益（+11.5 F1），但仍存在代码切换与拼写变体错误。  
4. **错误分析**：  
   - 约 20 % 失败因检索无关文档；  
   - 约 15 % 因模型“误读”非拉丁字符，输出乱码或英语。  

## 4. 贡献与局限  
### 4.1 主要贡献  
1. 首个覆盖 13 语言的 mRAG 全链路基线；  
2. 量化了“查询翻译 vs. 原语检索”在 recall 与生成层面的权衡；  
3. 提供代码与可重现评测脚本，便于后续工作对比。  

### 4.2 已知局限  
- 对 **非拉丁低资源**（阿拉伯、泰卢固）仍会出现 code-switch、语法不通顺；  
- 评测仅使用公开百科语料，真实行业/领域文档噪声更高；  
- 未深入探讨跨语言 reranker（如 ColBERT-X）在 RAG 中的作用。  

## 5. 对您课题的可借鉴点  
1. **pipeline 复用**：若后续实验需支持日/英/中三语检索，可直接采用论文开源脚本改动语言列表，再结合您已有向量库。  
2. **Prompt 模板**：在多语答复要求下，可仿照作者做法：  
   ```
   你是...<系统角色>  
   文档片段：{context}  
   问题（{lang}）：{query}  
   请使用{lang}回答，禁止切换到其他语言。
   ```  
3. **评测指标**：老师的 comment 中提到“结果要能对齐不同拼写”，可采用本文的 Unicode 归一+实体松匹配策略。  
4. **后续改进方向**：  
   - 引入跨语 reranker（如 ColBERT-XM）降低无关检索；  
   - 结合您已有的领域语料，做 **混合索引**（通用 + 领域）验证 domain shift；  
   - 针对低资源语言，可尝试 retrieval-translation-generation 级联，或采用 NLLB-200 翻译检索结果再生成。  

## 6. 参考实现资源  
- 代码仓库（作者提供）：https://github.com/naver/mrag-baseline  
- 预训练检索模型：`mcontriever-multilingual`（HuggingFace）  
- 生成模型 checkpoint：`google/mt5-xl`  

---

**快速 Checklist（与任务清单对应）**  
- [x] 阅读 MRAG 论文并总结  
- [ ] 在本地跑通 mRAG 基线 → 复现 XOR-TyDi 实验  
- [ ] 替换/扩充成您论文主题的多语专用语料  
- [ ] 根据老师 comment 优化评测与展示  
