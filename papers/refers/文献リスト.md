## ① 引用

\[1] Chirkova A, Gunturi B, Hollenstein N, et al. Retrieval-augmented generation in multilingual settings\[EB/OL]. 2024.
\[2] Asai A, Min S, Chen D, et al. XOR QA: Cross-lingual open-retrieval question answering\[EB/OL]. 2020.
\[3] Hung C-C, Green T, Litschko R, et al. ZusammenQA: Data augmentation for COQA\[EB/OL]. 2022.
\[4] Gupta S, Ranjan R, Singh S N. A comprehensive survey of retrieval-augmented generation (RAG): Evolution, current landscape and future directions\[EB/OL]. 2024.
\[5] Sharma N, Murray K, Xiao Z. Faux Polyglot: Information disparity in multilingual LLMs\[EB/OL]. 2024.
\[6] Lewis P, Oğuz B, Riedel S, et al. Retrieval-augmented generation for knowledge-intensive NLP tasks\[EB/OL]. 2020.
\[7] Ranaldi L, Haddow B, Birch A. Multilingual retrieval-augmented generation for knowledge-intensive task\[EB/OL]. 2025.
\[8] Chirkova A, Gunturi B, Hollenstein N, et al. Retrieval-augmented generation in multilingual settings\[EB/OL]. 2024.
\[9] Park J, Lee H. Investigating language preference of multilingual RAG systems\[EB/OL]. 2025.
\[10] Elmahdy A, Lin S-C, Ahmad A. Synergistic approach for simultaneous optimization of monolingual, cross-lingual, and multilingual information retrieval\[EB/OL]. 2024.
\[11] Liu W, Trenous S, Ribeiro L F R, et al. XRAG: Cross-lingual retrieval-augmented generation\[EB/OL]. 2025.
\[12] Wu S, Tang J, Yang B, et al. Not all languages are equal: Insights into multilingual retrieval-augmented generation\[EB/OL]. 2024.
\[13] Li B, Luo F, Haider S, et al. Multilingual RAG for culturally-sensitive tasks: A benchmark for cross-lingual robustness\[EB/OL]. 2024.
\[14] Asai A, Yu X, Kasai J, et al. One question answering model for many languages with cross-lingual dense passage retrieval\[EB/OL]. 2021.
\[15] Qi J, Fernández R, Bisazza A. On the consistency of multilingual context utilization in retrieval-augmented generation\[EB/OL]. 2025.
\[16] Amiraz C, Fyodorov Y, Haramaty E, et al. The cross-lingual cost: Retrieval biases in RAG over Arabic-English corpora\[EB/OL]. 2025.

---

## ② 要約

| #  | 要約                                                                                                                                        | リンク                                                                                    |
| -- | ------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |
| 1  | **mRAG の強力ベースライン**。13 言語で RAG パイプラインを徹底検証し、タスク固有プロンプトの重要性とコードスイッチングへの耐性を示した | [https://arxiv.org/abs/2407.01463](https://arxiv.org/abs/2407.01463)                         |
| 2  | **XOR-QA ベンチマーク**。質問言語と回答文書言語が異なる 7 言語・4 万 QA ペアを収録し、クロスリンガル QA 研究の礎を築いた              | [https://aclanthology.org/2021.naacl-main.46/](https://aclanthology.org/2021.naacl-main.46/) |
| 3  | **ZusammenQA**。COQA 共有タスク向けに、多段データ拡張とマルチモジュール統合で性能を大幅向上させた                                     | [https://aclanthology.org/2022.mia-1.8/](https://aclanthology.org/2022.mia-1.8/)             |
| 4  | **RAG 技術の体系的レビュー**。基礎から最新動向（エージェント指向・マルチモーダル・KG 連携など）まで網羅                               | [https://arxiv.org/abs/2410.12837](https://arxiv.org/abs/2410.12837)                         |
| 5  | **Faux Polyglot**。mLLM の情報偏在を実証し、低資源言語への不公平を定量化した                                                          | [https://arxiv.org/abs/2407.05502](https://arxiv.org/abs/2407.05502)                         |
| 6  | **RAG 元祖モデル**。パラメトリック＋非パラメトリック記憶を統合するフレームワークを提案                                                | [https://arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)                         |
| 7  | **CrossRAG**。取得文書を英語翻訳してから生成することで、多言語 QA を大幅向上                                                          | [https://arxiv.org/abs/2504.03616](https://arxiv.org/abs/2504.03616)                         |
| 8  | **mRAG**。プロンプト設計と評価指標の課題、コードスイッチング事例を詳述                                                                | [https://arxiv.org/pdf/2407.01463](https://arxiv.org/pdf/2407.01463)                         |
| 9  | **DKM-RAG**。取得文書と翻訳文書を融合し、検索・生成の言語バイアスを緩和                                                               | [https://arxiv.org/abs/2502.11175](https://arxiv.org/abs/2502.11175)                         |
| 10 | **Synergistic IR**。ハイブリッド学習で単言語・クロス言語・多言語検索を同時最適化                                                      | [https://arxiv.org/abs/2408.10536](https://arxiv.org/abs/2408.10536)                         |
| 11 | **XRAG ベンチマーク**。モノリンガル／マルチリンガル双方の難題を提示し、LLM の推論限界を可視化                                         | [https://arxiv.org/abs/2505.10089](https://arxiv.org/abs/2505.10089)                         |
| 12 | **Futurepedia ベンチ**。8 言語並列データで RAG の言語間不均衡を分析、英語優遇の傾向を報告                                             | [https://arxiv.org/abs/2410.21970](https://arxiv.org/abs/2410.21970)                         |
| 13 | **BordIRLines**。領土紛争データセット (49 言語) を用い、文化的バイアスと多言語ロバスト性を評価                                        | [https://arxiv.org/abs/2410.01171](https://arxiv.org/abs/2410.01171)                         |
| 14 | **CORA モデル**。クロスリンガル DPR と生成モデルを統合し、26 言語で従来比大幅改善を達成                                               | [https://arxiv.org/abs/2107.11976](https://arxiv.org/abs/2107.11976)                         |
| 15 | **文脈利用の一貫性分析**。LLM が異言語文脈をどこまで活用できるかを分離評価                                                            | [https://arxiv.org/abs/2504.00597](https://arxiv.org/abs/2504.00597)                         |
| 16 | **Cross-Lingual Cost**。アラビア語-英語社内コーパスで、取得言語の偏りが性能低下の主要因と判明                                         | [https://arxiv.org/abs/2507.07543](https://arxiv.org/abs/2507.07543)                         |


---

## 📝 关键先行研究（研究动机）

### 1. Chirkova et al. (2024) –** ***Retrieval‑augmented generation in multilingual settings*

* 研究涵盖了13种语言的 mRAG 基线系统，发现主要问题包括：
  * **频繁 code‑switching** （非拉丁语系中夹杂其它语言）
  * 生成输出中的** ****流畅性错误**
  * **检索结果不相关**或“错误读取检索文档” ([arXiv](https://arxiv.org/html/2407.01463v1?utm_source=chatgpt.com "Retrieval-augmented generation in multilingual settings - arXiv"))
    这些直接指出 mRAG 在生成一致性与检索准确性上的不足。

---

### 2. Wu et al. (2024) –** ***Not All Languages are Equal: Insights into Multilingual RAG*

* 构造 Futurepedia 基准，揭示多语言 RAG 存在资源不均衡的问题：
  * 高资源语言（如英语）在检索与生成中被优先选取
  * 低资源语言常被忽略或边缘化 ([arXiv](https://arxiv.org/abs/2410.21970?utm_source=chatgpt.com "Not All Languages are Equal: Insights into Multilingual Retrieval-Augmented Generation"))
    为研究中强调检索覆盖控制、多语言平衡提供了依据。

---

### 3. Park & Lee (2025) –** ***Investigating Language Preference of Multilingual RAG Systems*

* 系统性分析发现 RAG 系统在三个方面存偏置：
  * 检索器偏向高资源语言与查询语言
  * 生成器倾向采用 Latin 字母或查询语言
  * 导致输出不一致，多语言源之间可能冲突 ([arXiv](https://arxiv.org/abs/2502.11175?utm_source=chatgpt.com "Investigating Language Preference of Multilingual RAG Systems"))
    这为你在构建 LBRAG 时「检索偏好控制」与「生成语言决策」的设计提供直接支撑。

---

### 4. Ranaldi et al. (2025) –** ***Multilingual RAG for Knowledge‑Intensive Tasks*

* 提出 tRAG、MultiRAG、CrossRAG 三种策略比较，结果显示：
  * tRAG 覆盖率较低
  * MultiRAG 检索效率虽提升，但语言不一致问题严重
  * CrossRAG 改善质量，但带来翻译与一致性成本 ([Hugging Face](https://huggingface.co/papers/2502.11175?utm_source=chatgpt.com "Investigating Language Preference of Multilingual RAG Systems"),** **[arXiv](https://arxiv.org/abs/2504.03616?utm_source=chatgpt.com "Multilingual Retrieval-Augmented Generation for Knowledge-Intensive Task"))
    这为引入语言控制机制（prompt 控制）提供了实际弱点指向。