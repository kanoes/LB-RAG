## ① 引用

\[1] Chirkova A, Gunturi B, Hollenstein N, et al. Retrieval-augmented generation in multilingual settings\[EB/OL]. 2024.
\[2] Asai A, Min S, Chen D, et al. XOR QA: Cross-lingual open-retrieval question answering\[EB/OL]. 2020.
\[3] Hung C-C, Green T, Litschko R, et al. ZusammenQA: Data augmentation for COQA\[EB/OL]. 2022.
\[4] Gupta S, Ranjan R, Singh S N. A comprehensive survey of retrieval-augmented generation (RAG): Evolution, current landscape and future directions\[EB/OL]. 2024.
\[5] Sharma N, Murray K, Xiao Z. Faux Polyglot: Information disparity in multilingual LLMs\[EB/OL]. 2024.
\[6] Lewis P, Oğuz B, Riedel S, et al. Retrieval-augmented generation for knowledge-intensive NLP tasks\[EB/OL]. 2020.
\[7] Ranaldi L, Haddow B, Birch A. Multilingual retrieval-augmented generation for knowledge-intensive task\[EB/OL]. 2025.
\[8] Chirkova A, Gunturi B, Hollenstein N, et al. Retrieval-augmented generation in multilingual settings\[EB/OL]. 2024.
\[9] Park J, Lee H. Investigating language preference of multilingual RAG systems\[EB/OL]. 2025.
\[10] Elmahdy A, Lin S-C, Ahmad A. Synergistic approach for simultaneous optimization of monolingual, cross-lingual, and multilingual information retrieval\[EB/OL]. 2024.
\[11] Liu W, Trenous S, Ribeiro L F R, et al. XRAG: Cross-lingual retrieval-augmented generation\[EB/OL]. 2025.
\[12] Wu S, Tang J, Yang B, et al. Not all languages are equal: Insights into multilingual retrieval-augmented generation\[EB/OL]. 2024.
\[13] Li B, Luo F, Haider S, et al. Multilingual RAG for culturally-sensitive tasks: A benchmark for cross-lingual robustness\[EB/OL]. 2024.
\[14] Asai A, Yu X, Kasai J, et al. One question answering model for many languages with cross-lingual dense passage retrieval\[EB/OL]. 2021.
\[15] Qi J, Fernández R, Bisazza A. On the consistency of multilingual context utilization in retrieval-augmented generation\[EB/OL]. 2025.
\[16] Amiraz C, Fyodorov Y, Haramaty E, et al. The cross-lingual cost: Retrieval biases in RAG over Arabic-English corpora\[EB/OL]. 2025.

---

## ② 要約

| #  | 要約                                                                                                                                        | リンク                                                                                    |
| -- | ------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |
| 1  | **mRAG の強力ベースライン**。13 言語で RAG パイプラインを徹底検証し、タスク固有プロンプトの重要性とコードスイッチングへの耐性を示した | [https://arxiv.org/abs/2407.01463](https://arxiv.org/abs/2407.01463)                         |
| 2  | **XOR-QA ベンチマーク**。質問言語と回答文書言語が異なる 7 言語・4 万 QA ペアを収録し、クロスリンガル QA 研究の礎を築いた              | [https://aclanthology.org/2021.naacl-main.46/](https://aclanthology.org/2021.naacl-main.46/) |
| 3  | **ZusammenQA**。COQA 共有タスク向けに、多段データ拡張とマルチモジュール統合で性能を大幅向上させた                                     | [https://aclanthology.org/2022.mia-1.8/](https://aclanthology.org/2022.mia-1.8/)             |
| 4  | **RAG 技術の体系的レビュー**。基礎から最新動向（エージェント指向・マルチモーダル・KG 連携など）まで網羅                               | [https://arxiv.org/abs/2410.12837](https://arxiv.org/abs/2410.12837)                         |
| 5  | **Faux Polyglot**。mLLM の情報偏在を実証し、低資源言語への不公平を定量化した                                                          | [https://arxiv.org/abs/2407.05502](https://arxiv.org/abs/2407.05502)                         |
| 6  | **RAG 元祖モデル**。パラメトリック＋非パラメトリック記憶を統合するフレームワークを提案                                                | [https://arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)                         |
| 7  | **CrossRAG**。取得文書を英語翻訳してから生成することで、多言語 QA を大幅向上                                                          | [https://arxiv.org/abs/2504.03616](https://arxiv.org/abs/2504.03616)                         |
| 8  | **mRAG**。プロンプト設計と評価指標の課題、コードスイッチング事例を詳述                                                                | [https://arxiv.org/pdf/2407.01463](https://arxiv.org/pdf/2407.01463)                         |
| 9  | **DKM-RAG**。取得文書と翻訳文書を融合し、検索・生成の言語バイアスを緩和                                                               | [https://arxiv.org/abs/2502.11175](https://arxiv.org/abs/2502.11175)                         |
| 10 | **Synergistic IR**。ハイブリッド学習で単言語・クロス言語・多言語検索を同時最適化                                                      | [https://arxiv.org/abs/2408.10536](https://arxiv.org/abs/2408.10536)                         |
| 11 | **XRAG ベンチマーク**。モノリンガル／マルチリンガル双方の難題を提示し、LLM の推論限界を可視化                                         | [https://arxiv.org/abs/2505.10089](https://arxiv.org/abs/2505.10089)                         |
| 12 | **Futurepedia ベンチ**。8 言語並列データで RAG の言語間不均衡を分析、英語優遇の傾向を報告                                             | [https://arxiv.org/abs/2410.21970](https://arxiv.org/abs/2410.21970)                         |
| 13 | **BordIRLines**。領土紛争データセット (49 言語) を用い、文化的バイアスと多言語ロバスト性を評価                                        | [https://arxiv.org/abs/2410.01171](https://arxiv.org/abs/2410.01171)                         |
| 14 | **CORA モデル**。クロスリンガル DPR と生成モデルを統合し、26 言語で従来比大幅改善を達成                                               | [https://arxiv.org/abs/2107.11976](https://arxiv.org/abs/2107.11976)                         |
| 15 | **文脈利用の一貫性分析**。LLM が異言語文脈をどこまで活用できるかを分離評価                                                            | [https://arxiv.org/abs/2504.00597](https://arxiv.org/abs/2504.00597)                         |
| 16 | **Cross-Lingual Cost**。アラビア語-英語社内コーパスで、取得言語の偏りが性能低下の主要因と判明                                         | [https://arxiv.org/abs/2507.07543](https://arxiv.org/abs/2507.07543)                         |

---
